{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amy/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "# from GaussianGenerativeModel import GaussianGenerativeModel\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import KFold\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "try:\n",
    "    import xml.etree.cElementTree as ET\n",
    "except ImportError:\n",
    "    import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_feats(ffs, direc=\"train\", global_feat_dict=None):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      ffs are a list of feature-functions.\n",
    "      direc is a directory containing xml files (expected to be train or test).\n",
    "      global_feat_dict is a dictionary mapping feature_names to column-numbers; it\n",
    "      should only be provided when extracting features from test data, so that \n",
    "      the columns of the test matrix align correctly.\n",
    "\n",
    "    returns: \n",
    "      a sparse design matrix, a dict mapping features to column-numbers,\n",
    "      a vector of target classes, and a list of system-call-history ids in order \n",
    "      of their rows in the design matrix.\n",
    "      \n",
    "      Note: the vector of target classes returned will contain the true indices of the\n",
    "      target classes on the training data, but will contain only -1's on the test\n",
    "      data\n",
    "    \"\"\"\n",
    "    fds = [] # list of feature dicts\n",
    "    classes = []\n",
    "    ids = [] \n",
    "    #datafile: filename(without path)\n",
    "    for datafile in os.listdir(direc):\n",
    "        # extract id and true class (if available) from filename\n",
    "        id_str,clazz = datafile.split('.')[:2] #id_str: id  #clazz: class name for this file\n",
    "        ids.append(id_str)\n",
    "        # add target class if this is training data\n",
    "        try:\n",
    "            classes.append(util.malware_classes.index(clazz))\n",
    "        except ValueError:\n",
    "            # we should only fail to find the label in our list of malware classes\n",
    "            # if this is test data, which always has an \"X\" label\n",
    "            assert clazz == \"X\"\n",
    "            classes.append(-1)\n",
    "        rowfd = {}\n",
    "        # parse file as an xml document\n",
    "        tree = ET.parse(os.path.join(direc,datafile)) #direc: train     datafile: the whole file name\n",
    "        \n",
    "        \n",
    "        # accumulate features\n",
    "        [rowfd.update(ff(tree)) for ff in ffs]\n",
    "        fds.append(rowfd)\n",
    "        \n",
    "    X,feat_dict = make_design_mat(fds,global_feat_dict)\n",
    "    return X, feat_dict, np.array(classes), ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Here are two example feature-functions. They each take an xml.etree.ElementTree object, \n",
    "# (i.e., the result of parsing an xml file) and returns a dictionary mapping \n",
    "# feature-names to numeric values.\n",
    "## TODO: modify these functions, and/or add new ones.\n",
    "def first_last_system_call_feats(tree):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      tree is an xml.etree.ElementTree object\n",
    "    returns:\n",
    "      a dictionary mapping 'first_call-x' to 1 if x was the first system call\n",
    "      made, and 'last_call-y' to 1 if y was the last system call made. \n",
    "      (in other words, it returns a dictionary indicating what the first and \n",
    "      last system calls made by an executable were.)\n",
    "    \"\"\"\n",
    "    c = Counter()\n",
    "    in_all_section = False\n",
    "    first = True # is this the first system call\n",
    "    last_call = None # keep track of last call we've seen\n",
    "    for el in tree.iter():\n",
    "        # ignore everything outside the \"all_section\" element  \n",
    "        if el.tag == \"all_section\" and not in_all_section:\n",
    "            in_all_section = True\n",
    "        elif el.tag == \"all_section\" and in_all_section:\n",
    "            in_all_section = False\n",
    "        elif in_all_section:\n",
    "            if first:\n",
    "                c[\"first_call-\"+el.tag] = 1\n",
    "                first = False\n",
    "            last_call = el.tag  # update last call seen\n",
    "            \n",
    "    # finally, mark last call seen\n",
    "    c[\"last_call-\"+last_call] = 1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def system_call_count_feats(tree):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      tree is an xml.etree.ElementTree object\n",
    "    returns:\n",
    "      a dictionary mapping 'num_system_calls' to the number of system_calls\n",
    "      made by an executable (summed over all processes)\n",
    "    \"\"\"\n",
    "    c = Counter()\n",
    "    in_all_section = False\n",
    "    for el in tree.iter():\n",
    "        # ignore everything outside the \"all_section\" element\n",
    "        if el.tag == \"all_section\" and not in_all_section:\n",
    "            in_all_section = True\n",
    "        elif el.tag == \"all_section\" and in_all_section:\n",
    "            in_all_section = False\n",
    "        elif in_all_section:\n",
    "            c['num_system_calls'] += 1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_design_mat(fds, global_feat_dict=None):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      fds is a list of feature dicts (one for each row).\n",
    "      global_feat_dict is a dictionary mapping feature_names to column-numbers; it\n",
    "      should only be provided when extracting features from test data, so that \n",
    "      the columns of the test matrix align correctly.\n",
    "       \n",
    "    returns: \n",
    "        a sparse NxD design matrix, where N == len(fds) and D is the number of\n",
    "        the union of features defined in any of the fds \n",
    "    \"\"\"\n",
    "    if global_feat_dict is None:\n",
    "        all_feats = set()\n",
    "        [all_feats.update(fd.keys()) for fd in fds]\n",
    "        feat_dict = dict([(feat, i) for i, feat in enumerate(sorted(all_feats))])\n",
    "    else:\n",
    "        feat_dict = global_feat_dict\n",
    "        \n",
    "    cols = []\n",
    "    rows = []\n",
    "    data = []        \n",
    "    for i in xrange(len(fds)):\n",
    "        temp_cols = []\n",
    "        temp_data = []\n",
    "        for feat,val in fds[i].iteritems():\n",
    "            try:\n",
    "                # update temp_cols iff update temp_data\n",
    "                temp_cols.append(feat_dict[feat])\n",
    "                temp_data.append(val)\n",
    "            except KeyError as ex:\n",
    "                if global_feat_dict is not None:\n",
    "                    pass  # new feature in test data; nbd\n",
    "                else:\n",
    "                    raise ex\n",
    "\n",
    "        # all fd's features in the same row\n",
    "        k = len(temp_cols)\n",
    "        cols.extend(temp_cols)\n",
    "        data.extend(temp_data)\n",
    "        rows.extend([i]*k)\n",
    "\n",
    "    assert len(cols) == len(rows) and len(rows) == len(data)\n",
    "   \n",
    "\n",
    "    X = sparse.csr_matrix((np.array(data),\n",
    "                   (np.array(rows), np.array(cols))),\n",
    "                   shape=(len(fds), len(feat_dict)))\n",
    "    return X, feat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add our functions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exist_VBA(tree):\n",
    "    c = Counter()\n",
    "    for el in tree.iter():\n",
    "        # ignore everything outside the \"all_section\" element\n",
    "        if el.tag == \"open_key\" and  \"key\" in el.attrib.keys() and \"VBA\" in el.attrib['key']:\n",
    "            c['exist_VBA'] = 1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def exist_VBA_getusername(tree):\n",
    "    c = Counter()\n",
    "    found_VBA = False\n",
    "    #found_getusername = False\n",
    "    for el in tree.iter():\n",
    "        # ignore everything outside the \"all_section\" element\n",
    "        if el.tag == \"open_key\" and  \"key\" in el.attrib.keys() and \"VBA\" in el.attrib['key']:\n",
    "            found_VBA = True\n",
    "        if found_VBA== True and el.tag == \"get_username\":\n",
    "            #found_getusername = True\n",
    "            c['exist_VBA_getusername'] = 1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exist_Swizzor_0002DF(tree):\n",
    "    c = Counter()\n",
    "    for el in tree.iter():\n",
    "        # ignore everything outside the \"all_section\" element\n",
    "        if el.tag == \"open_key\" and  \"key\" in el.attrib.keys() and \"0002DF01-0000-0000-C000-000000000046\" in el.attrib['key']:\n",
    "            c['exist_Swizzor_0002DF'] = 1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_system_call_count(tree):\n",
    "    c = Counter()\n",
    "    in_all_section = False\n",
    "    for el in tree.iter():\n",
    "        # ignore everything outside the \"all_section\" element  \n",
    "        if el.tag == \"all_section\" and not in_all_section:\n",
    "            in_all_section = True\n",
    "        elif el.tag == \"all_section\" and in_all_section:\n",
    "            in_all_section = False\n",
    "        elif in_all_section:\n",
    "                c[\"call-\"+el.tag] += 1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to calculate accuracy\n",
    "def model_accuracy(y, y_pred):\n",
    "    p = (np.array(y) == np.array(y_pred))\n",
    "    return float(p.sum())/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting training features...\n",
      "done extracting training features\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"train\"\n",
    "test_dir = \"test\"\n",
    "outputfile = \"mypredictions_rf.csv\"  # feel free to change this or take it as an argument\n",
    "\n",
    "# TODO put the names of the feature functions you've defined above in this list\n",
    "ffs = [all_system_call_count]\n",
    "\n",
    "# extract features\n",
    "print \"extracting training features...\"\n",
    "X_train,global_feat_dict,t_train,train_ids = extract_feats(ffs, train_dir)\n",
    "#sparse feature matrix, feature dict with its column index, class name, file idea\n",
    "print \"done extracting training features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3086, 102)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_matrix = X_train.toarray()\n",
    "feat_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Split training files randomly as 7:3\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(feat_matrix, t_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2160,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Use 5-fold cross validation to tune parameters\n",
    "RF_score = []\n",
    "kf = KFold(n = x_train.shape[0], n_folds=5)\n",
    "\n",
    "n_est_regularization = np.arange(5, 30, 5)\n",
    "n_ft_regularization = np.arange(20, 100, 10)\n",
    "for c in n_est_regularization:\n",
    "    for c1 in n_ft_regularization:\n",
    "        rf_score = []\n",
    "        rf = RandomForestClassifier(n_estimators = c, max_features = c1)\n",
    "        for train_index, test_index in kf:\n",
    "            train_x, test_x = x_train[train_index], x_train[test_index]\n",
    "            train_y, test_y = y_train[train_index], y_train[test_index]\n",
    "            rf.fit(train_x, train_y)\n",
    "            rf_score.append(rf.score(test_x,test_y))\n",
    "        RF_score.append((c,c1, np.average(rf_score)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 40, 0.88518518518518507)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(RF_score,key=itemgetter(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8909287257019438"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test Score\n",
    "rf = RandomForestClassifier( n_estimators = 20, max_features = 40 )\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "model_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=40, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=20, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the parameter, train the whole train file\n",
    "rf = RandomForestClassifier( n_estimators = 20, max_features = 40 )\n",
    "rf.fit(feat_matrix, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting training features...\n",
      "done extracting training features\n"
     ]
    }
   ],
   "source": [
    "#Extract feature matrix of test files\n",
    "print \"extracting training features...\"\n",
    "X_test,test_feat_dict,t_test,test_ids = extract_feats(ffs, test_dir, global_feat_dict=global_feat_dict)\n",
    "#sparse feature matrix, feature dict with its column index, class name, file idea\n",
    "print \"done extracting training features\"\n",
    "test_feat_matrix=X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predict\n",
    "y_pred_test = rf.predict(test_feat_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing predictions...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print \"writing predictions...\"\n",
    "util.write_predictions(y_pred_test, test_ids, outputfile)\n",
    "print \"done!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "ET_score = []\n",
    "kf = KFold(n = x_train.shape[0], n_folds=5)\n",
    "\n",
    "n_est_regularization = np.arange(5, 30, 5)\n",
    "n_ft_regularization = np.arange(20, 100, 10)\n",
    "for c in n_est_regularization:\n",
    "    for c1 in n_ft_regularization:\n",
    "        et_score = []\n",
    "        et = ExtraTreesClassifier(n_estimators = c, max_features = c1)\n",
    "        for train_index, test_index in kf:\n",
    "            train_x, test_x = x_train[train_index], x_train[test_index]\n",
    "            train_y, test_y = y_train[train_index], y_train[test_index]\n",
    "            et.fit(train_x, train_y)\n",
    "            et_score.append(et.score(test_x,test_y))\n",
    "        ET_score.append((c,c1, np.average(et_score)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 30, 0.88287037037037042)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(ET_score,key=itemgetter(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8984881209503239"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get test score\n",
    "et = ExtraTreesClassifier(n_estimators = 25, max_features = 30 )\n",
    "et.fit(x_train, y_train)\n",
    "\n",
    "y_pred = et.predict(x_test)\n",
    "model_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features=30, max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=25, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the parameter, train the whole train file\n",
    "et = ExtraTreesClassifier( n_estimators = 25, max_features = 30 )\n",
    "et.fit(feat_matrix, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8, 10,  8, ..., 12,  8,  0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict\n",
    "y_pred_test  = et.predict(test_feat_matrix)\n",
    "y_pred_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing predictions...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "outputfile = \"mypredictions_ET.csv\"\n",
    "print \"writing predictions...\"\n",
    "util.write_predictions(y_pred_test, test_ids, outputfile)\n",
    "print \"done!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28077753779697623"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gnb.predict(x_test)\n",
    "model_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Random forest with new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest with 1 new features: exist_VBA_getusername"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting training features...\n",
      "done extracting training features\n"
     ]
    }
   ],
   "source": [
    "outputfile = \"mypredictions_rf_VBA.csv\"  # feel free to change this or take it as an argument\n",
    "\n",
    "# TODO put the names of the feature functions you've defined above in this list\n",
    "ffs = [all_system_call_count, exist_VBA_getusername]\n",
    "\n",
    "# extract features\n",
    "print \"extracting training features...\"\n",
    "X_train,global_feat_dict,t_train,train_ids = extract_feats(ffs, train_dir)\n",
    "#sparse feature matrix, feature dict with its column index, class name, file idea\n",
    "print \"done extracting training features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3086, 103)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_matrix = X_train.toarray()\n",
    "feat_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(feat_matrix, t_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2160,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "RF_score = []\n",
    "kf = KFold(n = x_train.shape[0], n_folds=5)\n",
    "\n",
    "n_est_regularization = np.arange(5, 30, 5)\n",
    "n_ft_regularization = np.arange(20, 100, 10)\n",
    "for c in n_est_regularization:\n",
    "    for c1 in n_ft_regularization:\n",
    "        rf_score = []\n",
    "        rf = RandomForestClassifier(n_estimators = c, max_features = c1)\n",
    "        for train_index, test_index in kf:\n",
    "            train_x, test_x = x_train[train_index], x_train[test_index]\n",
    "            train_y, test_y = y_train[train_index], y_train[test_index]\n",
    "            rf.fit(train_x, train_y)\n",
    "            rf_score.append(rf.score(test_x,test_y))\n",
    "        RF_score.append((c,c1, np.average(rf_score)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 40, 0.8842592592592593)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(RF_score,key=itemgetter(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=40, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=15, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier( n_estimators = 15, max_features = 40 )\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8822894168466523"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get test score\n",
    "y_pred = rf.predict(x_test)\n",
    "model_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest with 1 new features: exist_Swizzor_0002DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting training features...\n",
      "done extracting training features\n"
     ]
    }
   ],
   "source": [
    "outputfile = \"mypredictions_rf_Swizzor.csv\"  # feel free to change this or take it as an argument\n",
    "\n",
    "# TODO put the names of the feature functions you've defined above in this list\n",
    "ffs = [all_system_call_count, exist_Swizzor_0002DF]\n",
    "\n",
    "# extract features\n",
    "print \"extracting training features...\"\n",
    "X_train,global_feat_dict,t_train,train_ids = extract_feats(ffs, train_dir)\n",
    "#sparse feature matrix, feature dict with its column index, class name, file idea\n",
    "print \"done extracting training features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3086, 103)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_matrix = X_train.toarray()\n",
    "feat_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(feat_matrix, t_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "RF_score = []\n",
    "kf = KFold(n = x_train.shape[0], n_folds=5)\n",
    "\n",
    "n_est_regularization = np.arange(5, 30, 5)\n",
    "n_ft_regularization = np.arange(20, 100, 10)\n",
    "for c in n_est_regularization:\n",
    "    for c1 in n_ft_regularization:\n",
    "        rf_score = []\n",
    "        rf = RandomForestClassifier(n_estimators = c, max_features = c1)\n",
    "        for train_index, test_index in kf:\n",
    "            train_x, test_x = x_train[train_index], x_train[test_index]\n",
    "            train_y, test_y = y_train[train_index], y_train[test_index]\n",
    "            rf.fit(train_x, train_y)\n",
    "            rf_score.append(rf.score(test_x,test_y))\n",
    "        RF_score.append((c,c1, np.average(rf_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 30, 0.88564814814814807)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(RF_score,key=itemgetter(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8876889848812095"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test score\n",
    "rf = RandomForestClassifier( n_estimators = 25, max_features = 30 )\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(x_test)\n",
    "model_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest with 2 new features: exist_VBA_getusername, exist_Swizzor_0002DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting training features...\n",
      "done extracting training features\n"
     ]
    }
   ],
   "source": [
    "outputfile = \"mypredictions_rf_VBA.csv\"  # feel free to change this or take it as an argument\n",
    "\n",
    "# TODO put the names of the feature functions you've defined above in this list\n",
    "ffs = [all_system_call_count, exist_VBA_getusername, exist_Swizzor_0002DF]\n",
    "\n",
    "# extract features\n",
    "print \"extracting training features...\"\n",
    "X_train,global_feat_dict,t_train,train_ids = extract_feats(ffs, train_dir)\n",
    "#sparse feature matrix, feature dict with its column index, class name, file idea\n",
    "print \"done extracting training features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3086, 104)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_matrix = X_train.toarray()\n",
    "feat_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(feat_matrix, t_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "RF_score = []\n",
    "kf = KFold(n = x_train.shape[0], n_folds=5)\n",
    "\n",
    "n_est_regularization = np.arange(5, 30, 5)\n",
    "n_ft_regularization = np.arange(20, 100, 10)\n",
    "for c in n_est_regularization:\n",
    "    for c1 in n_ft_regularization:\n",
    "        rf_score = []\n",
    "        rf = RandomForestClassifier(n_estimators = c, max_features = c1)\n",
    "        for train_index, test_index in kf:\n",
    "            train_x, test_x = x_train[train_index], x_train[test_index]\n",
    "            train_y, test_y = y_train[train_index], y_train[test_index]\n",
    "            rf.fit(train_x, train_y)\n",
    "            rf_score.append(rf.score(test_x,test_y))\n",
    "        RF_score.append((c,c1, np.average(rf_score)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 50, 0.88472222222222219)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(RF_score,key=itemgetter(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8833693304535637"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get test score\n",
    "rf = RandomForestClassifier( n_estimators = 25, max_features = 50 )\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(x_test)\n",
    "model_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only use the 102 feature now, extract features again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting training features...\n",
      "done extracting training features\n"
     ]
    }
   ],
   "source": [
    "outputfile = \"mypredictions_dt.csv\"  # feel free to change this or take it as an argument\n",
    "\n",
    "# TODO put the names of the feature functions you've defined above in this list\n",
    "ffs = [all_system_call_count]\n",
    "\n",
    "# extract features\n",
    "print \"extracting training features...\"\n",
    "X_train,global_feat_dict,t_train,train_ids = extract_feats(ffs, train_dir)\n",
    "#sparse feature matrix, feature dict with its column index, class name, file idea\n",
    "print \"done extracting training features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3086, 102)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_matrix = X_train.toarray()\n",
    "feat_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(feat_matrix, t_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "DT_score = []\n",
    "kf = KFold(n = len(x_train), n_folds=5)\n",
    "for c in range(1,100):\n",
    "    dt_score = []\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=c)\n",
    "    for train_index, test_index in kf:\n",
    "        train_x, test_x = x_train[train_index], x_train[test_index]\n",
    "        train_y, test_y = y_train[train_index], y_train[test_index]\n",
    "        clf.fit(train_x, train_y)\n",
    "        dt_score.append(clf.score(test_x, test_y))\n",
    "    DT_score.append(np.average(dt_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_score.index(max(DT_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=13,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=13)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8606911447084233"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "model_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=13,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now train on the whole dataset\n",
    "clf = tree.DecisionTreeClassifier(max_depth=13)\n",
    "clf.fit(feat_matrix, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting training features...\n",
      "done extracting training features\n"
     ]
    }
   ],
   "source": [
    "#Extract feature matrix of test files\n",
    "print \"extracting training features...\"\n",
    "X_test,test_feat_dict,t_test,test_ids = extract_feats(ffs, test_dir, global_feat_dict=global_feat_dict)\n",
    "#sparse feature matrix, feature dict with its column index, class name, file idea\n",
    "print \"done extracting training features\"\n",
    "test_feat_matrix=X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8, 10,  7, ..., 12,  8,  8])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict\n",
    "y_pred_test = clf.predict(test_feat_matrix)\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing predictions...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print \"writing predictions...\"\n",
    "util.write_predictions(y_pred_test, test_ids, outputfile)\n",
    "print \"done!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8736501079913607"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = GradientBoostingClassifier(n_estimators=60, learning_rate=0.01,\n",
    "     max_depth= 5, random_state=5, loss='deviance')\n",
    "est.fit(x_train, y_train)\n",
    "y_pred = est.predict(x_test)\n",
    "model_accuracy(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.01, loss='deviance', max_depth=5,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=60, presort='auto', random_state=5,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now train on the whole dataset\n",
    "est.fit(feat_matrix, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8, 10,  8, ..., 12,  8,  8])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now use actual test file\n",
    "y_test_pred = est.predict(test_feat_matrix)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing predictions...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print \"writing predictions...\"\n",
    "outputfile = \"mypredictions_ensemble.csv\"\n",
    "util.write_predictions(y_test_pred, test_ids, outputfile)\n",
    "print \"done!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## SVC - with class prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cs = [pow(10, i) for i in range(-5, 5)]\n",
    "Cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight = [3.69, 1.62, 1.20, 1.03, 1.33, 1.26, 1.72, 1.33, 52.14, 0.68, 17.56, 1.04, 12.18, 1.91, 1.30]\n",
    "weights = [x/100 for x in weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0369,\n",
       " 1: 0.016200000000000003,\n",
       " 2: 0.012,\n",
       " 3: 0.0103,\n",
       " 4: 0.013300000000000001,\n",
       " 5: 0.0126,\n",
       " 6: 0.0172,\n",
       " 7: 0.013300000000000001,\n",
       " 8: 0.5214,\n",
       " 9: 0.0068000000000000005,\n",
       " 10: 0.17559999999999998,\n",
       " 11: 0.0104,\n",
       " 12: 0.12179999999999999,\n",
       " 13: 0.0191,\n",
       " 14: 0.013000000000000001}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_dict = dict(zip(range(15),weights))\n",
    "weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SVC_score = []\n",
    "kf = KFold(n = len(x_train), n_folds=5)\n",
    "for c in Cs:\n",
    "    svc_score = []\n",
    "    svcmodel = SVC(kernel='rbf', C=c, class_weight = weight_dict)\n",
    "    for train_index, test_index in kf:\n",
    "        train_x, test_x = x_train[train_index], x_train[test_index]\n",
    "        train_y, test_y = y_train[train_index], y_train[test_index]\n",
    "        svcmodel.fit(train_x, train_y)\n",
    "        svc_score.append(svcmodel.score(test_x, test_y))\n",
    "    SVC_score.append(np.average(svc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_score.index(max(SVC_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cs[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7980561555075594"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svcmodel = SVC(kernel='rbf', C=1000, class_weight = weight_dict)\n",
    "svcmodel.fit(x_train, y_train)\n",
    "y_pred = svcmodel.predict(x_test)\n",
    "model_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with class prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RF_score = []\n",
    "kf = KFold(n = x_train.shape[0], n_folds=5)\n",
    "\n",
    "n_est_regularization = np.arange(5, 30, 5)\n",
    "n_ft_regularization = np.arange(20, 100, 10)\n",
    "for c in n_est_regularization:\n",
    "    for c1 in n_ft_regularization:\n",
    "        rf_score = []\n",
    "        rf = RandomForestClassifier(n_estimators = c, max_features = c1, class_weight = weight_dict)\n",
    "        for train_index, test_index in kf:\n",
    "            train_x, test_x = x_train[train_index], x_train[test_index]\n",
    "            train_y, test_y = y_train[train_index], y_train[test_index]\n",
    "            rf.fit(train_x, train_y)\n",
    "            rf_score.append(rf.score(test_x,test_y))\n",
    "        RF_score.append((c,c1, np.average(rf_score)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 20, 0.87870370370370365)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(RF_score,key=itemgetter(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8855291576673866"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier( n_estimators = 15, max_features = 20, class_weight = weight_dict)\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "model_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True,\n",
       "            class_weight={0: 0.0369, 1: 0.016200000000000003, 2: 0.012, 3: 0.0103, 4: 0.013300000000000001, 5: 0.0126, 6: 0.0172, 7: 0.013300000000000001, 8: 0.5214, 9: 0.0068000000000000005, 10: 0.17559999999999998, 11: 0.0104, 12: 0.12179999999999999, 13: 0.0191, 14: 0.013000000000000001},\n",
       "            criterion='gini', max_depth=None, max_features=20,\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the parameter, train the whole train file\n",
    "rf = RandomForestClassifier( n_estimators = 15, max_features = 20, class_weight = weight_dict)\n",
    "rf.fit(feat_matrix, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8, 10,  4, ..., 12,  8,  0])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = rf.predict(test_feat_matrix)\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing predictions...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print \"writing predictions...\"\n",
    "outputfile = \"mypredictions_rf_prior.csv\"\n",
    "util.write_predictions(y_pred_test, test_ids, outputfile)\n",
    "print \"done!\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
